{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fM7b0vkhvAe"
      },
      "source": [
        "# Generating images with MX-Font model from a reference style\n",
        "In this example we'll generate images with trained MX-Font model from a reference style.\n",
        "If you want to generate multiple styles, please check using `eval.py` instead of using this example file (because it is much simpler to load the referece styles)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpEhCekIoNdx",
        "outputId": "04012536-cdd8-47d0-dbb8-5e1a55c23674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64VqAMUOhvAi"
      },
      "source": [
        "### 1. Loading packages\n",
        "* First, load the packages used in this code.\n",
        "* All of the packages are avilable in `pip`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sconf"
      ],
      "metadata": {
        "id": "-gVFM8l7iayN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58fab89d-f3de-4160-c0e0-8a986d01c979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sconf\n",
            "  Downloading sconf-0.2.5-py3-none-any.whl (8.8 kB)\n",
            "Collecting ruamel.yaml (from sconf)\n",
            "  Downloading ruamel.yaml-0.18.5-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting munch (from sconf)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml->sconf)\n",
            "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ruamel.yaml.clib, munch, ruamel.yaml, sconf\n",
            "Successfully installed munch-4.0.0 ruamel.yaml-0.18.5 ruamel.yaml.clib-0.2.8 sconf-0.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2hCFVxwjVtt",
        "outputId": "c6a23562-b6df-41ae-b5d4-62f589b23f0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/2023학교/AIKU/2023_2_project2/mxfont-main\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFZf18SKkcMc",
        "outputId": "9aff8d12-76b5-414e-f173-44e3c0f46ec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/2023학교/AIKU/2023_2_project2/mxfont-main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy scipy scikit-image tqdm jsonlib-python3 fonttools"
      ],
      "metadata": {
        "id": "qUcxCPnEmEa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6cad1e9-74ec-4275-c7c0-f4a2a4bf8bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Collecting jsonlib-python3\n",
            "  Downloading jsonlib-python3-1.6.1.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: fonttools in /usr/local/lib/python3.10/dist-packages (4.46.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2023.12.9)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (23.2)\n",
            "Building wheels for collected packages: jsonlib-python3\n",
            "  Building wheel for jsonlib-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonlib-python3: filename=jsonlib_python3-1.6.1-cp310-cp310-linux_x86_64.whl size=72615 sha256=57b8c7d66e889145100a200e8260ce5b239c6fc5d308de5e28e79a64052335d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/48/2b/3b4e8a617b152bacc255f98c81f38f099b1ac06209d6c48d8a\n",
            "Successfully built jsonlib-python3\n",
            "Installing collected packages: jsonlib-python3\n",
            "Successfully installed jsonlib-python3-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zB8HzHK2hvAj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from sconf import Config\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW3Ph4SEhvAk"
      },
      "source": [
        "* These modules are defined in this repository."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/My Drive/mxfont/mxfont\")"
      ],
      "metadata": {
        "id": "7S62QjWln7bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJWjN0mThvAl"
      },
      "outputs": [],
      "source": [
        "import models\n",
        "from datasets import read_font, render\n",
        "from utils import save_tensor_to_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTJW945vhvAl"
      },
      "source": [
        "### 2. Build model\n",
        "* Build and load the trained model.\n",
        "* `weight_path` :\n",
        "    * The location of the trained model weight."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x52CSSnozMS",
        "outputId": "ddbcbba2-ff2a-4bb7-a535-db5a9bf72786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaBWZ2wyxnfm",
        "outputId": "f3d2d89c-b0a9-47aa-f07a-385d58ffbf6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/2023학교/AIKU/2023_2_project2/mxfont-main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8GUEc0uhvAl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "797fed04-bc3b-41f1-8bfd-da959d480bf5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "########################################################\n",
        "weight_path = \"/content/drive/MyDrive/2023학교/AIKU/2023_2_project2/mxfont-main/train_results/2023_12_24_09:54:18/checkpoints/018000.pth\"\n",
        "#weight_path = \"/content/drive/MyDrive/2023학교/AIKU/2023_2_project2/mxfont-main/train_results/2023_11_30_08:27:41/checkpoints/027000.pth\"  # path to weight to infer\n",
        "#weight_path = \"/content/drive/MyDrive/2023학교/AIKU/2023_2_project2/mxfont-main/train_results/2023_11_29_21:36:41/last.pth\"\n",
        "#weight_path = \"/content/drive/MyDrive/2023학교/AIKU/2023_2_project2/mxfont-main/generator.pth\"\n",
        "########################################################\n",
        "\n",
        "cfg = Config(\"/content/drive/MyDrive/2023학교/AIKU/2023_2_project2/mxfont-main/cfgs/eval.yaml\", default=\"/content/drive/MyDrive/2023학교/AIKU/2023_2_project2/mxfont-main/cfgs/defaults.yaml\")\n",
        "transform = transforms.Compose(\n",
        "    [transforms.Grayscale(num_output_channels=1),transforms.Resize((128, 128)), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
        ")\n",
        "decomposition = json.load(open(\"/content/drive/MyDrive/fewshot-font-generation-main/data/kor/decomposition.json\"))\n",
        "\n",
        "g_kwargs = cfg.get('g_args', {})\n",
        "gen = models.Generator(1, cfg.C, 1, **g_kwargs).cuda().eval()\n",
        "weight = torch.load(weight_path)\n",
        "if \"generator_ema\" in weight:\n",
        "    weight = weight[\"generator_ema\"]\n",
        "gen.load_state_dict(weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKXKQwyXhvAn"
      },
      "source": [
        "### 3. Load reference images.\n",
        "* `ref_path`:\n",
        "    * The path of reference font or images.\n",
        "    * If you are using a ttf file, set this to the location of the ttf file.\n",
        "    * If you want to use rendered images, set this to the path to the directory which contains the reference images.\n",
        "* `extension`:\n",
        "    * If you are using image files, set this to their extension(png, jpg, etc..).\n",
        "    * This will be ignored if `use_ttf` is True.\n",
        "* `batch_size`:\n",
        "    * The number of images inferred at once."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdb"
      ],
      "metadata": {
        "id": "eD9ZwUsr3fPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyCE1mp-hvAo"
      },
      "outputs": [],
      "source": [
        "########################################################\n",
        "ref_path = \"/content/drive/MyDrive/2023학교/AIKU/2023_2_project2/mxfont-main/data/images/test/MaShanZheng-Regular\"  # Path to the reference images\n",
        "extension = \"png\"  # Extension of the reference images\n",
        "batch_size = 3  # The batch size\n",
        "########################################################\n",
        "\n",
        "ref_paths = Path(ref_path).glob(f\"*.{extension}\")\n",
        "#temp_img = [transform(Image.open(str(p))) for p in ref_paths]\n",
        "#pdb.set_trace()\n",
        "ref_imgs = torch.stack([transform(Image.open(str(p))) for p in ref_paths]).cuda()\n",
        "ref_batches = torch.split(ref_imgs, batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZDd6xNWhvAo"
      },
      "source": [
        "### 4. Extract style factors from reference images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ys1HTAXhvAp"
      },
      "outputs": [],
      "source": [
        "style_facts = {}\n",
        "import numpy as np\n",
        "for batch in ref_batches:\n",
        "    style_fact = gen.factorize(gen.encode(batch), 0)\n",
        "    for k in style_fact:\n",
        "        style_facts.setdefault(k, []).append(style_fact[k])\n",
        "style_facts = {k: torch.cat(v).mean(0, keepdim=True) for k, v in style_facts.items()}\n",
        "#rdn = random.randrange(70,100)\n",
        "#style_facts['last'] = style_facts['last'] + torch.randint(rdn,size=(1,6,256,16,16)).cuda()\n",
        "#style_facts['skip'] = style_facts['last'] + torch.rand(1,6,256,16,16).cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3QAaIN3hvAq"
      },
      "source": [
        "### 5. Generate the images.\n",
        "* `gen_chars`: The characters to generate.\n",
        "* `save_dir`: Path to save the generated images.\n",
        "* `source_path`: Path to the font file used as the source font."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "random.seed(100)"
      ],
      "metadata": {
        "id": "WPO4UDK4Jo8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "sYSTcB8IVyP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wKJjvTehvAr"
      },
      "outputs": [],
      "source": [
        "def denoise(img):\n",
        "    # 이진화\n",
        "    _, binary = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # 노이즈 제거\n",
        "    kernel = np.ones((3,3), np.uint8)  # 노이즈 제거에 사용할 커널 설정\n",
        "    closing = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel) # 글자 내부 노이즈 제거\n",
        "    opening = cv2.morphologyEx(closing, cv2.MORPH_OPEN, kernel) # 바깥 노이즈 제거\n",
        "\n",
        "    # 흰색 배경 제거하고 검정색 글자만 남기기\n",
        "    mask = closing != 255  # 흰색이 아닌 부분만 True로 설정\n",
        "    transparent_img = np.zeros((closing.shape[0], closing.shape[1], 4), dtype=np.uint8)  # RGBA 이미지를 위한 빈 Canvas 생성\n",
        "    transparent_img[mask, 0:3] = 0  # 검정색 글자 설정\n",
        "    transparent_img[mask, 3] = 255  # 흰색이 아닌 부분은 불투명하게\n",
        "\n",
        "    # 결과 이미지 보기\n",
        "    #plt.imshow(transparent_img)\n",
        "    #plt.axis('off')\n",
        "    #plt.show()\n",
        "\n",
        "    #cv2.imwrite('output.png', transparent_img)\n",
        "    return transparent_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsrQXRlahvAq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e6055c0-8240-4227-99d1-2669e0af0fe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "(100, 700, 3)\n",
            "(100, 700, 3) 100 700\n",
            "(100, 700) (100, 700, 3)\n",
            "(100, 700) (100, 700, 3)\n",
            "(599, 800, 3)\n",
            "(100, 700)\n",
            "(100, 700, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "########################################################\n",
        "gen_chars = \"아이쿠 화이팅\"  # Characters to generate\n",
        "ref_style = ref_path.split(\"/\")[-1]\n",
        "checkpoint = (weight_path.split(\"/\")[-1]).split(\".\")[0]\n",
        "folder_name = datetime.today().strftime(\"%Y_%m_%d_%H:%M:%S\")\n",
        "save_dir = Path(f\"./results/{checkpoint}_{ref_style}_{folder_name}_{gen_chars}\")  # Directory where you want to save generated images\n",
        "source_path = \"/content/drive/MyDrive/2023학교/AIKU/2023_2_project2/source_ttf/gungseo.ttf\"  # Path to the font file to render the source images\n",
        "########################################################\n",
        "\n",
        "\n",
        "\"\"\"# variation\n",
        "cfg['seed'] = random.random()\n",
        "cfg['g_args']['experts']['n_experts'] = 6\n",
        "gen = models.Generator(1, cfg.C, 1, **g_kwargs).cuda().eval()\n",
        "weight = torch.load(weight_path)\n",
        "if \"generator_ema\" in weight:\n",
        "    weight = weight[\"generator_ema\"]\n",
        "gen.load_state_dict(weight)\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "source_font = read_font(source_path)\n",
        "cnt = Counter(gen_chars)\n",
        "crop_list = []\n",
        "for char in gen_chars:\n",
        "    path = save_dir / f\"{char}_{cnt[char]}.png\"\n",
        "    if char == ' ' :\n",
        "        print(char)\n",
        "        space = np.full((128, 128, 3), 255, dtype = np.uint8)\n",
        "        im = Image.fromarray(space)\n",
        "        im.save(path)\n",
        "    else :\n",
        "        source_img = transform(render(source_font, char)).unsqueeze(0).cuda()\n",
        "        char_facts = gen.factorize(gen.encode(source_img), 1)\n",
        "        rdn = random.randrange(1,85)\n",
        "\n",
        "        #random_noise = torch.from_numpy(np.random.normal(size=(1,6,256,16,16))).type(torch.FloatTensor)\n",
        "        #random_noise = torch.from_numpy(np.random.poisson(lam=20, size=(1,6,256,16,16))).type(torch.FloatTensor)\n",
        "        #random_noise = torch.from_numpy(np.random.uniform(low=0.0, high=rdn, size=(1,6,256,16,16))).type(torch.FloatTensor)\n",
        "        #char_facts['last'] = char_facts['last'] + random_noise.cuda()\n",
        "        #char_facts['last'] = char_facts['last'] + torch.randint(rdn,size=(1,6,256,16,16)).cuda()\n",
        "        #char_facts['skip'] = torch.empty(1, 6, 128, 32, 32).cuda()\n",
        "\n",
        "        gen_feats = gen.defactorize([style_facts, char_facts])\n",
        "        out = gen.decode(gen_feats).detach().cpu()[0]\n",
        "        #pdb.set_trace()\n",
        "        #out = out.cuda() + torch.rand(1,128,128).cuda()\n",
        "\n",
        "        cnt[char] -= 1\n",
        "        save_tensor_to_image(out, path)\n",
        "\n",
        "    img = cv2.imread(str(path))\n",
        "    if img is None:\n",
        "        print(f\"ERROR: CANNOT READ {char}.png\")\n",
        "    else:\n",
        "      tmpimg = img[17:117, 12:116]\n",
        "      crop_list.append(tmpimg)\n",
        "\n",
        "CROP_RESULT = cv2.hconcat(crop_list)\n",
        "cv2.imwrite(str(save_dir / \"concat_complete.png\"), CROP_RESULT)\n",
        "concat_img = cv2.imread(str(save_dir / \"concat_complete.png\"), cv2.IMREAD_GRAYSCALE)  # 그레이스케일로 이미지 불러오기\n",
        "\n",
        "img_fg = denoise(concat_img)\n",
        "img_bg = cv2.imread('/content/drive/MyDrive/2023학교/AIKU/2023_2_project2/mxfont-main/background_letter/hobbang.png')\n",
        "\n",
        "#--② 알파채널을 이용해서 마스크와 역마스크 생성\n",
        "img_fg = cv2.resize(img_fg, dsize=(700,100),interpolation=cv2.INTER_AREA)\n",
        "_, mask = cv2.threshold(img_fg[:,:,3], 1, 255, cv2.THRESH_BINARY)\n",
        "mask_inv = cv2.bitwise_not(mask)\n",
        "\n",
        "#--③ 전경 영상 크기로 배경 영상에서 ROI 잘라내기\n",
        "img_fg = cv2.cvtColor(img_fg, cv2.COLOR_BGRA2BGR)\n",
        "print(img_fg.shape)\n",
        "h, w = img_fg.shape[:2]\n",
        "print(img_fg.shape,h,w)\n",
        "roi = img_bg[70:70+h,10:10+w ]\n",
        "\n",
        "#--④ 마스크 이용해서 오려내기\n",
        "print(mask.shape, img_fg.shape)\n",
        "print(mask_inv.shape, roi.shape)\n",
        "print(img_bg.shape)\n",
        "masked_fg = cv2.bitwise_and(img_fg, img_fg, mask=mask)\n",
        "print(mask_inv.shape)\n",
        "print(roi.shape)\n",
        "masked_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
        "\n",
        "#--⑥ 이미지 합성\n",
        "added = masked_fg + masked_bg\n",
        "img_bg[70:70+h, 10:10+w] = added\n",
        "\n",
        "cv2.imwrite(str(save_dir / \"final_complete.png\"), img_bg)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fdz9aIguPSxS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}